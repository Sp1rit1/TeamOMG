{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cb19d9dc-f21e-4bf4-8227-5068af4d436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from deeppavlov import build_model, configs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "44a36134-6649-40f0-99ff-27fd9dc33ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  качество плохое пошив ужасный (горловина напер...  negative\n",
      "1  Товар отдали другому человеку, я не получила п...  negative\n",
      "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
      "3  товар не пришел, продавец продлил защиту без м...  negative\n",
      "4      Кофточка голая синтетика, носить не возможно.  negative\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "negative    30000\n",
      "neautral    30000\n",
      "positive    30000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('women-clothing-accessories.3-class.balanced.csv', encoding=\"utf-8\", engine='python', sep='\\t')\n",
    "print(df.head())\n",
    "\n",
    "# Проверка на наличие пропущенных значений\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Анализ распределения классов\n",
    "print(df['sentiment'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e0039eed-657c-4116-9f2a-186e660096ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Векторизация текста с использованием CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "67dcf878-4ca7-4d0e-a7ef-f86ab27a00ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0001\\anaconda3\\envs\\deeppavlov_venv\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.6203333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.49      0.68      0.57      6060\n",
      "    negative       0.65      0.52      0.58      5942\n",
      "    positive       0.80      0.66      0.72      5998\n",
      "\n",
      "    accuracy                           0.62     18000\n",
      "   macro avg       0.65      0.62      0.63     18000\n",
      "weighted avg       0.65      0.62      0.63     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 1: KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_vec, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test_vec)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ef5adf6e-6290-4fb1-9f53-e504c35c3187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.6751666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.54      0.68      0.60      6060\n",
      "    negative       0.71      0.63      0.67      5942\n",
      "    positive       0.84      0.71      0.77      5998\n",
      "\n",
      "    accuracy                           0.68     18000\n",
      "   macro avg       0.70      0.67      0.68     18000\n",
      "weighted avg       0.70      0.68      0.68     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Модель 2: GradientBoostingClassifier\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_vec, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_vec)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fd9b58e2-3897-4fe9-ade2-84b8945bdc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0001\\anaconda3\\envs\\deeppavlov_venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7217777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.62      0.61      0.62      6060\n",
      "    negative       0.71      0.71      0.71      5942\n",
      "    positive       0.84      0.85      0.84      5998\n",
      "\n",
      "    accuracy                           0.72     18000\n",
      "   macro avg       0.72      0.72      0.72     18000\n",
      "weighted avg       0.72      0.72      0.72     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC  # Используем LinearSVC \n",
    "\n",
    "# Модель 3: LinearSVC\n",
    "svm_model = LinearSVC(random_state=42, class_weight='balanced')  # Учитываем несбалансированность классов\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_vec)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "56d73411-9bf3-42a8-afae-a4df7c532a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 22:21:40.834 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/classifiers/rusentiment_convers_bert/rusentiment_convers_bert_torch.tar.gz download because of matching hashes\n",
      "C:\\Users\\0001\\anaconda3\\envs\\deeppavlov_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-03-20 22:21:42.824 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersClassifierModel on GPU, since no CUDA GPUs are available. Using CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPavlov Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00         2\n",
      "     neutral       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.56      0.67      0.60         5\n",
      "weighted avg       0.67      0.80      0.72         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0001\\AppData\\Local\\Temp\\ipykernel_5016\\341309078.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[\"predicted_sentiment\"] = new_df[\"review\"].apply(get_sentiment)\n",
      "C:\\Users\\0001\\anaconda3\\envs\\deeppavlov_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\0001\\anaconda3\\envs\\deeppavlov_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\0001\\anaconda3\\envs\\deeppavlov_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "new_df = df.head(100)\n",
    "\n",
    "# Загрузка предобученной модели анализа тональности\n",
    "sentiment_model = build_model(configs.classifiers.rusentiment_convers_bert, download=True)\n",
    "\n",
    "# Функция для определения тональности текста\n",
    "def get_sentiment(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"neutral\"  # Если текст пустой или не строка, возвращаем нейтральную тональность\n",
    "    return sentiment_model([text])[0]\n",
    "\n",
    "\n",
    "# Применение модели анализа тональности\n",
    "new_df[\"predicted_sentiment\"] = new_df[\"review\"].apply(get_sentiment)\n",
    "\n",
    "# Вычисление метрик\n",
    "print(\"DeepPavlov Accuracy:\", accuracy_score(new_df[\"sentiment\"], new_df[\"predicted_sentiment\"]))\n",
    "print(classification_report(new_df[\"sentiment\"], new_df[\"predicted_sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2fdd8476-128a-414f-bbb9-4044a54e2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Сравнение результатов\n",
    "results = {\n",
    "    'SVM Accuracy:': accuracy_score(y_test, y_pred_svm),\n",
    "    'KNN Accuracy:': accuracy_score(y_test, y_pred_knn),\n",
    "    'Gradient Boosting: ': accuracy_score(y_test, y_pred_gb),\n",
    "    'DeepPavlov Accuracy: ': accuracy_score(new_df[\"sentiment\"], new_df[\"predicted_sentiment\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5fedb1d9-e311-4ddd-9d51-a4c11f74fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy:: 0.7218\n",
      "KNN Accuracy:: 0.6203\n",
      "Gradient Boosting: : 0.6752\n",
      "DeepPavlov Accuracy: : 0.8000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeppavlov_venv",
   "language": "python",
   "name": "deeppavlov_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
