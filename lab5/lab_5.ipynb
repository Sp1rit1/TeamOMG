{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å Mistral 7B(Ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è...\n",
      "\n",
      "‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞:\n",
      "–ù–∞–∑–≤–∞–Ω–∏–µ: –¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –ï8-S-32 (–î—É 32)\n",
      "–¶–µ–Ω–∞: 41 501 —Ä—É–±.\n",
      "–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n",
      "  –ú–∞—Ç–µ—Ä–∏–∞–ª: –£–≥–ª–µ—Ä–æ–¥–∏—Å—Ç–∞—è —Å—Ç–∞–ª—å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)\n",
      "  –†–∞—Å—á–µ—Ç–Ω–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, ¬∞–°: 150\n",
      "  –î—É —Ç–µ–ø–ª–æ–æ–±–µ–Ω–Ω–∏–∫–∞: 32\n",
      "  –û–±—ä–µ–º –±–∞–∫–∞, –ª: 4,6\n",
      "  –°—Ö–µ–º–∞ –ø–æ—Ç–æ–∫–æ–≤: –û–¥–Ω–æ—Ö–æ–¥–æ–≤–æ–π\n",
      "  –°—Ä–µ–¥–∞ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ: –í–æ–¥–∞\n",
      "  –°—Ä–µ–¥–∞ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ: –í–æ–¥–∞\n",
      "  –†–∞—Å—Ö–æ–¥ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ: 11,2 —Ç—á\n",
      "  –†–∞—Å—Ö–æ–¥ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ: 4,67 —Ç—á\n",
      "  –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—Ö–æ–¥–µ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 95\n",
      "  –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—Ö–æ–¥–µ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 5\n",
      "  –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 70\n",
      "  –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 65\n",
      "  –ü–æ—Ç–µ—Ä–∏ –¥–∞–≤–ª–µ–Ω–∏—è –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ: 29,73 –∫–ü–∞\n",
      "  –ü–æ—Ç–µ—Ä–∏ –¥–∞–≤–ª–µ–Ω–∏—è –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ: 5,76 –∫–ü–∞\n",
      "  –¢–µ–ø–ª–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: 280000 –∫–∫–∞–ª—á\n",
      "  –ó–∞–ø–∞—Å –ø–ª–æ—â–∞–¥–∏ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏, %: 16,1\n",
      "  –ö–æ—ç—Ñ. —Ç–µ–ø–ª–æ–ø–µ—Ä–µ–¥–∞—á–∏: 4017\n",
      "  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–ª–æ—â–∞–¥—å, –º2: 2\n",
      "  –ß–∏—Å–ª–æ –ø–ª–∞—Å—Ç–∏–Ω: 50\n",
      "  –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è: –†–µ–∑—å–±–æ–≤–æ–µ\n",
      "  –ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ—Ä—Ç–æ–≤: -\n",
      "  –û—Ç–≤–µ—Ç–Ω—ã–µ —Ñ–ª–∞–Ω—Ü—ã: -\n",
      "  –†–∞—Å—á–µ—Ç–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ: 10\n",
      "  –ü—Ä–æ–±–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ, –∫–≥/—Å/—Å–º2: 14\n",
      "  –ú–∞—Å—Å–∞ –Ω–µ—Ç—Ç–æ, –∫–≥: 38,8\n",
      "  –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –æ–±—ä–µ–º, –ª: 4,6\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ: ...\n",
      "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (5): ['data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==', 'https://e8company.ru/upload/adwex.minified/webp/2ad/90/2adac2ba323374c0f1c96dcda9b1b76b.webp']...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "class E8CompanyParser:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "\n",
    "    def parse_equipment_page(self, url: str) -> dict:\n",
    "        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "            data = {\n",
    "                'name': self._extract_equipment_name(response.text),\n",
    "                'price': self._extract_price(soup),\n",
    "                'specs': self._extract_specs(soup),\n",
    "                'description': self._get_text(soup, 'div.product__desc'),\n",
    "                'images': self._extract_images(soup),\n",
    "                'link': url\n",
    "            }\n",
    "            \n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def _extract_equipment_name(self, html: str) -> str:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\"\"\"\n",
    "        try:\n",
    "            # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –≤ –ª—é–±–æ–º —Ç–µ–≥–µ —Å id=\"pagetitle\"\n",
    "            pagetitle_match = re.search(r'<[^>]*id=[\"\\']pagetitle[\"\\'][^>]*>(.*?)</', html, re.DOTALL)\n",
    "            if pagetitle_match:\n",
    "                name = self._clean_text(pagetitle_match.group(1))\n",
    "                if name and name != \"== $0\":\n",
    "                    return name\n",
    "            \n",
    "            # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –≤ title —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n",
    "            title_match = re.search(r'<title>(.*?)</title>', html, re.DOTALL)\n",
    "            if title_match:\n",
    "                title = self._clean_text(title_match.group(1))\n",
    "                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ title\n",
    "                name_match = re.search(r'^(.*?)(?:\\s*[|-]|\\s*–∫—É–ø–∏—Ç—å)', title)\n",
    "                if name_match:\n",
    "                    return name_match.group(1).strip()\n",
    "                return title\n",
    "            \n",
    "            # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ h1\n",
    "            h1_match = re.search(r'<h1[^>]*>(.*?)</h1>', html, re.DOTALL)\n",
    "            if h1_match:\n",
    "                return self._clean_text(h1_match.group(1))\n",
    "            \n",
    "            return \"–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return \"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è\"\n",
    "\n",
    "    def _extract_specs(self, soup: BeautifulSoup) -> dict:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\"\"\"\n",
    "        specs = {}\n",
    "        try:\n",
    "            rows = soup.find_all('tr')\n",
    "            for row in rows:\n",
    "                name = row.find('td', class_='char_name') or row.find('th')\n",
    "                value = row.find('td', class_='char_value') or row.find('td')\n",
    "                if name and value:\n",
    "                    key = self._clean_text(name.get_text())\n",
    "                    val = self._clean_text(value.get_text())\n",
    "                    if key and val:\n",
    "                        specs[key] = val\n",
    "        except Exception:\n",
    "            pass\n",
    "        return specs\n",
    "\n",
    "    def _extract_price(self, soup: BeautifulSoup) -> str:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã\"\"\"\n",
    "        try:\n",
    "            price_block = soup.find('div', class_='product__price') or \\\n",
    "                         soup.find('span', class_='price') or \\\n",
    "                         soup.find('div', class_='price')\n",
    "            if price_block:\n",
    "                price = price_block.find('span') or price_block\n",
    "                return self._clean_text(price.get_text())\n",
    "            return \"–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞\"\n",
    "        except Exception:\n",
    "            return \"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ü–µ–Ω—ã\"\n",
    "\n",
    "    def _extract_images(self, soup: BeautifulSoup) -> list:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
    "        images = []\n",
    "        try:\n",
    "            for img in soup.find_all('img'):\n",
    "                src = img.get('src') or img.get('data-src')\n",
    "                if src:\n",
    "                    img_url = urljoin('https://e8company.ru', src)\n",
    "                    if img_url not in images:\n",
    "                        images.append(img_url)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return images\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_text(soup: BeautifulSoup, selector: str) -> str:\n",
    "        \"\"\"–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä—É\"\"\"\n",
    "        try:\n",
    "            element = soup.select_one(selector)\n",
    "            return E8CompanyParser._clean_text(element.get_text()) if element else \"\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_text(text: str) -> str:\n",
    "        \"\"\"–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        try:\n",
    "            if not text:\n",
    "                return \"\"\n",
    "            text = re.sub(r'==\\s*\\$\\d+', '', text)\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            return text\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = E8CompanyParser()\n",
    "    test_url = \"https://e8company.ru/catalog/teploobmenniki/e8_teploobmenniki/e8_s_32/\"\n",
    "    \n",
    "    print(\"üîÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è...\")\n",
    "    equipment_data = parser.parse_equipment_page(test_url)\n",
    "    \n",
    "    print(\"\\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞:\")\n",
    "    print(f\"–ù–∞–∑–≤–∞–Ω–∏–µ: {equipment_data.get('name', '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ')}\")\n",
    "    print(f\"–¶–µ–Ω–∞: {equipment_data.get('price', '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É')}\")\n",
    "    print(\"–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\")\n",
    "    for key, value in equipment_data.get('specs', {}).items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"–û–ø–∏—Å–∞–Ω–∏–µ: {equipment_data.get('description', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è')[:200]}...\")\n",
    "    print(f\"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({len(equipment_data.get('images', []))}): {equipment_data.get('images', [])[:2]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –¥–∞–Ω–Ω–æ–º –∫–æ–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å GPT-2, —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0001\\anaconda3\\envs\\deeppavlov_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è: –ú–∏–∫—Ä–æ—Å–∫–æ–ø Olympus CX23\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å–∞–π—Ç–∞: HTTPSConnectionPool(host='www.biomedical.com', port=443): Max retries exceeded with url: /search?q=%D0%9C%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%BA%D0%BE%D0%BF%20Olympus%20CX23 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001B4F4801420>, 'Connection to www.biomedical.com timed out. (connect timeout=None)'))\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ —Å –≤–µ–±-–¥–∞–Ω–Ω—ã–º–∏:\n",
      "–í—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
      "–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä: Cortex A3\n",
      "–î–≤–∏–≥–∞—Ç–µ–ª—å: 2,5 –ª.—Å.\n",
      "–ú–æ—â–Ω–æ—Å—Ç—å: 4,3 –ª\n",
      "–ú–∞–∫—Å. —á–∞—Å—Ç–æ—Ç–∞: 8 –ì—Ü\n",
      "–î–∏–∞–ø–∞–∑–æ–Ω —Ä–∞–±–æ—á–∏—Ö —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä: –æ—Ç -20 –¥–æ +45 ¬∞–°\n",
      "–í—Ä–µ–º—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã: 30 –º–∏–Ω—É—Ç\n",
      "–û–±—ä–µ–º: 720 –º–ª\n",
      "–í–µ—Å: 3,1 –∫–≥\n",
      "–ì–∞–±–∞—Ä–∏—Ç—ã: 960x720x970 –º–º\n",
      "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:\n",
      "–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: MacBook Pro 940x655 (MacBoy) 970x450 (Ubunt\n",
      "\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ –±–µ–∑ –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö:\n",
      "Olympa C-Master –∏ Olympio CM-3, –∏–ª–∏, –∫–∞–∫ –∏—Ö –µ—â–µ –Ω–∞–∑—ã–≤–∞—é—Ç, ¬´—Ñ–ª–∞–≥–º–∞–Ω—Å–∫–∏–µ¬ª –æ–±—ä–µ–∫—Ç–∏–≤—ã Olympiac Olympo.\n",
      "\n",
      "¬´–§–ª–∞–≥–º–∞–Ω—ã¬ª ‚Äì –æ–±—ä–µ–∫—Ç–∏–≤–∞, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–≤–µ—Ä—Ö–ø—Ä–æ—á–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã. –ò—Ö –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äì –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å –≤—ã—Å–æ–∫—É—é —Å—Ç–µ–ø–µ–Ω—å —Å–∂–∞—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∞–µ–º–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –æ–ø—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–ø—Ç–∏–∫—É —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∑–∞–ø–∏—Å–∏ –∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –î–ª—è –æ–±—ä–µ–∫—Ç–∏–≤–æ–≤ —Å–æ —Å–≤–µ—Ä—Ö—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º —Å—Ç–µ–∫–ª–æ–º –∏ –º–∞—Ç—Ä–∏—Ü–µ–π —Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ–º 1600 —Ö 1200 –ø–∏–∫—Å–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–æ—Ñ—Ç-—Å–µ–Ω—Å–æ—Ä, –ø–æ–º–æ–≥–∞—é—â–∏–π —Å–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ –±–æ–ª–µ–µ —è—Ä–∫–∏–º. ¬´–§–ª–∞–≥–∏¬ª —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
      "\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è: –¶–µ–Ω—Ç—Ä–∏—Ñ—É–≥–∞ Eppendorf 5424\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å–∞–π—Ç–∞: HTTPSConnectionPool(host='www.biomedical.com', port=443): Max retries exceeded with url: /search?q=%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B8%D1%84%D1%83%D0%B3%D0%B0%20Eppendorf%205424 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001B4F4801510>, 'Connection to www.biomedical.com timed out. (connect timeout=None)'))\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ —Å –≤–µ–±-–¥–∞–Ω–Ω—ã–º–∏:\n",
      "–°—Ö–µ–º–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: EPN-—Å–µ—Ä–≤–µ—Ä—ã\n",
      "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: USB, 4 –ø–æ—Ä—Ç–∞, USB-–ø–æ—Ä—Ç\n",
      "–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞: Discovery\n",
      "–î–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –≤–Ω–µ—à–Ω–µ–≥–æ –ü–û: –≤–Ω–µ—à–Ω–∏–π –¥–∏—Å–∫\n",
      "–§–æ—Ä–º–∞—Ç: mp3-—Ñ–∞–π–ª, 128 –ú–±\n",
      "–¢–∏–ø –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è/—É–¥–∞–ª–µ–Ω–∏—è: NAT\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ: \n",
      "\n",
      "–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?\n",
      "–ê –≤–æ—Ç –∫–∞–∫: –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –≤–Ω–µ—à–Ω–µ–≥–æ (Windows)/Discount() –¥–∏—Å–∫–æ–≤–æ–¥–∞ –∫ –∫–æ–º–ø—å—é—Ç–µ—Ä—É (Disk) —Å –ø–æ–º–æ—â—å—é –≤–Ω–µ—à–Ω–µ–≥–æ –¥–∏—Å–∫–∞ –º—ã —É–¥–∞–ª—è–µ–º –∏–∑ –Ω–µ–≥–æ –≤—Å–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º\n",
      "\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ –±–µ–∑ –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö:\n",
      "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: –≠–ú–ü–î–†–û\n",
      "–°—Ö–µ–º–∞: EPD\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ: \n",
      "\n",
      "–≠–ú–ü–ò–†–û–í–ê–ù–ò–ï\n",
      "–ü—Ä–∏–±–æ—Ä: 1,6 –ì–ì—Ü\n",
      "–†–∞–∑–º–µ—Ä: 24 –ì–±\n",
      "–í–µ—Å: 15,9 –∫–≥\n",
      "–ù–∞–≤–∏–≥–∞—Ü–∏—è: –ø–æ –º–µ–Ω—é\n",
      "–ú–æ–≥—É –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞ –≤—ã–±–æ—Ä: –¥–ª—è —á—Ç–µ–Ω–∏—è, –ø—Ä–æ—Å–º–æ—Ç—Ä–∞, –∑–∞–ø–∏—Å–∏, –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∏ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ.\n",
      "–¶–µ–Ω–∞: 1280 —Ä—É–±–ª–µ–π. \n",
      " \n",
      " \n",
      "–î—Ä—É–≥–∏–µ —Ç–æ–≤–∞—Ä—ã –∏–∑ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:  \n",
      "   \n",
      "    \n",
      "            –°–µ–Ω—Å–æ—Ä–Ω—ã–π –¥–∞—Ç—á–∏–∫ –¥–≤–∏–∂–µ–Ω–∏—è  \n",
      "–ß–∞—Å—ã: 6.9 –¥—é–π–º–æ–≤\n",
      "   –ú–æ–¥–µ–ª—å:\n",
      "\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è: –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≥–µ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π Mindray BC-2800\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å–∞–π—Ç–∞: HTTPSConnectionPool(host='www.biomedical.com', port=443): Max retries exceeded with url: /search?q=%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%82%D0%BE%D1%80%20%D0%B3%D0%B5%D0%BC%D0%B0%D1%82%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9%20Mindray%20BC-2800 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001B4F4801CF0>, 'Connection to www.biomedical.com timed out. (connect timeout=None)'))\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ —Å –≤–µ–±-–¥–∞–Ω–Ω—ã–º–∏:\n",
      "–û–±—Ä–∞—â–∞–µ–º –í–∞—à–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ –¥–∞–Ω–Ω—ã–π —Å–∞–π—Ç –Ω–æ—Å–∏—Ç –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –Ω–∏ –ø—Ä–∏ –∫–∞–∫–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ —Ü–µ–Ω—ã, —Ä–∞–∑–º–µ—â–µ–Ω–Ω—ã–µ –Ω–∞ —Å–∞–π—Ç–µ, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø—É–±–ª–∏—á–Ω–æ–π –æ—Ñ–µ—Ä—Ç–æ–π, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º–æ–π –ø–æ–ª–æ–∂–µ–Ω–∏—è–º–∏ –°—Ç–∞—Ç—å–∏ 437 –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–§.\n",
      "–í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –í—ã –∑–∞–º–µ—Ç–∏–ª–∏ –∫–∞–∫–∏–µ-–ª–∏–±–æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ —Å–æ–æ–±—â–∏—Ç–µ –Ω–∞–º –æ–± —ç—Ç–æ–º. –í —Å–ª—É—á–∞–µ –Ω–µ–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –ø—Ä–æ—Å—å–±–∞ —Å–æ–æ–±—â–∏—Ç—å –Ω–∞–º –æ —Ñ–∞–∫—Ç–∞—Ö –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–µ–π. –ú—ã —Å —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –≤—Å–µ –í–∞—à–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.–° —É–≤–∞–∂–µ–Ω–∏–µ–º,–í–¢–ë 24 (–ü–ê–û)\n",
      "–°–∫–∞–∂–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–æ–≥–¥–∞ –°–±–µ—Ä–±–∞–Ω–∫ —Å–Ω–∏–∑–∏—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—É—é —Å—Ç–∞–≤–∫—É –≤ 2016 –≥–æ–¥—É?\n",
      "–î–æ–±—Ä—ã–π\n",
      "\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ –±–µ–∑ –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö:\n",
      "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:&nbsp;&nbsp; –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –¥–≤—É—Ö —Ä–µ–∂–∏–º–∞—Ö: &quot;–ì–µ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ&quot;, &nbsp;,&laquo;–û—á–∏—Å—Ç–∫–∞&raqursqua;.\n",
      "–¢–∏–ø: –†—É—á–Ω–æ–π.\n",
      "–†–∞–∑–º–µ—Ä: 16,5 –º–º. –®–∏—Ä–∏–Ω–∞: 0,8 –º–º\n",
      "–í–µ—Å: 1,7 –∫–≥\n",
      "–¶–µ–Ω–∞: 590 —Ä—É–±–ª–µ–π\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ: –í&rarr;—Ö–æ–¥—è—Ç –≤ —Å–æ—Å—Ç–∞–≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –∫—Ä–æ–≤–∏ Moodray —Å&auml;4-–∫–∞–Ω–∞–ª—å–Ω—ã–º –¥–∞—Ç—á–∏–∫–æ–º. –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π&hell\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from typing import List, Dict, Optional\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "class WebEquipmentScraper:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "    \n",
    "    def scrape_equipment_data(self, base_url: str, search_query: str = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ–± –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏ —Å –≤–µ–±-—Å–∞–π—Ç–∞\n",
    "        \n",
    "        :param base_url: URL —Å–∞–π—Ç–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞\n",
    "        :param search_query: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "        :return: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if search_query:\n",
    "                search_url = f\"{base_url}/search?q={search_query}\"\n",
    "                response = requests.get(search_url, headers=self.headers)\n",
    "            else:\n",
    "                response = requests.get(base_url, headers=self.headers)\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–∞–π—Ç–∞\n",
    "            equipment_items = soup.find_all('div', class_='equipment-item')  # –ü—Ä–∏–º–µ—Ä - –∏–∑–º–µ–Ω–∏—Ç–µ –ø–æ–¥ —Ü–µ–ª–µ–≤–æ–π —Å–∞–π—Ç\n",
    "            \n",
    "            results = []\n",
    "            for item in equipment_items:\n",
    "                name = item.find('h3').text.strip() if item.find('h3') else \"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ\"\n",
    "                description = item.find('div', class_='description').text.strip() if item.find('div', class_='description') else \"\"\n",
    "                specs = item.find('ul', class_='specs').text.strip() if item.find('ul', class_='specs') else \"\"\n",
    "                \n",
    "                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n",
    "                relative_link = item.find('a')['href'] if item.find('a') else None\n",
    "                full_link = urljoin(base_url, relative_link) if relative_link else \"\"\n",
    "                \n",
    "                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n",
    "                if full_link:\n",
    "                    detailed_data = self.scrape_equipment_details(full_link)\n",
    "                else:\n",
    "                    detailed_data = {}\n",
    "                \n",
    "                results.append({\n",
    "                    'name': name,\n",
    "                    'description': description,\n",
    "                    'specifications': specs,\n",
    "                    'link': full_link,\n",
    "                    **detailed_data\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å–∞–π—Ç–∞: {e}\")\n",
    "            return []\n",
    "\n",
    "    def scrape_equipment_details(self, url: str) -> Dict:\n",
    "        \"\"\"\n",
    "        –ü–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n",
    "        \n",
    "        :param url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n",
    "        :return: —Å–ª–æ–≤–∞—Ä—å —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ —ç—Ç–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ü–µ–ª–µ–≤–æ–≥–æ —Å–∞–π—Ç–∞\n",
    "            details = {\n",
    "                'full_description': soup.find('div', class_='full-description').text.strip() if soup.find('div', class_='full-description') else \"\",\n",
    "                'technical_specs': self.extract_technical_specs(soup),\n",
    "                'images': [img['src'] for img in soup.select('.equipment-gallery img')] if soup.select('.equipment-gallery img') else [],\n",
    "                'price': soup.find('span', class_='price').text.strip() if soup.find('span', class_='price') else \"–ù–µ —É–∫–∞–∑–∞–Ω–∞\"\n",
    "            }\n",
    "            \n",
    "            return details\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}\")\n",
    "            return {}\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_technical_specs(soup: BeautifulSoup) -> Dict:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ\"\"\"\n",
    "        specs = {}\n",
    "        spec_rows = soup.select('table.specs tr')  # –ü—Ä–∏–º–µ—Ä —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ - –∏–∑–º–µ–Ω–∏—Ç–µ –ø–æ–¥ —Ü–µ–ª–µ–≤–æ–π —Å–∞–π—Ç\n",
    "        \n",
    "        for row in spec_rows:\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) == 2:\n",
    "                key = cells[0].text.strip().rstrip(':')\n",
    "                value = cells[1].text.strip()\n",
    "                specs[key] = value\n",
    "                \n",
    "        return specs\n",
    "\n",
    "class EquipmentDescriptionGenerator:\n",
    "    def __init__(self, model_name: str = \"sberbank-ai/rugpt3small_based_on_gpt2\", use_web: bool = True):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞\n",
    "        \n",
    "        :param model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "        :param use_web: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name).to(self.device)\n",
    "        self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        \n",
    "        self.web_scraper = WebEquipmentScraper() if use_web else None\n",
    "        self.equipment_db = pd.DataFrame(columns=['name', 'description', 'specs', 'source'])\n",
    "    \n",
    "    def enrich_from_web(self, equipment_name: str, max_results: int = 3) -> None:\n",
    "        \"\"\"\n",
    "        –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π\n",
    "        \n",
    "        :param equipment_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "        :param max_results: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "        \"\"\"\n",
    "        if not self.web_scraper:\n",
    "            return\n",
    "        \n",
    "        # –ü—Ä–∏–º–µ—Ä—ã —Å–∞–π—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ)\n",
    "        sites_to_scrape = [\n",
    "            \"https://www.medwow.com\",\n",
    "            \"https://www.biomedical.com\"\n",
    "        ]\n",
    "        \n",
    "        for site in sites_to_scrape:\n",
    "            results = self.web_scraper.scrape_equipment_data(site, equipment_name)\n",
    "            for result in results[:max_results]:\n",
    "                if result['name'].lower() in equipment_name.lower() or equipment_name.lower() in result['name'].lower():\n",
    "                    description = result.get('full_description', result.get('description', ''))\n",
    "                    specs = result.get('technical_specs', result.get('specifications', {}))\n",
    "                    \n",
    "                    new_entry = {\n",
    "                        'name': result['name'],\n",
    "                        'description': description,\n",
    "                        'specs': str(specs),\n",
    "                        'source': result['link']\n",
    "                    }\n",
    "                    \n",
    "                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–∞–∫–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –µ—â–µ –Ω–µ—Ç –≤ –±–∞–∑–µ\n",
    "                    if not self.equipment_db[self.equipment_db['name'].str.contains(result['name'], case=False)].any().any():\n",
    "                        self.equipment_db = pd.concat([self.equipment_db, pd.DataFrame([new_entry])], ignore_index=True)\n",
    "    \n",
    "    def generate_description(self, equipment_name: str, use_web_data: bool = True, \n",
    "                           max_length: int = 150, temperature: float = 0.7) -> str:\n",
    "        \"\"\"\n",
    "        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö\n",
    "        \n",
    "        :param equipment_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n",
    "        :param use_web_data: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞\n",
    "        :param max_length: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è\n",
    "        :param temperature: –ø–∞—Ä–∞–º–µ—Ç—Ä \"—Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞\"\n",
    "        :return: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ\n",
    "        \"\"\"\n",
    "        if use_web_data and self.web_scraper:\n",
    "            self.enrich_from_web(equipment_name)\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ –Ω–∞—à–µ–π –±–∞–∑–µ\n",
    "        db_info = self.equipment_db[self.equipment_db['name'].str.contains(equipment_name, case=False)]\n",
    "        \n",
    "        if not db_info.empty:\n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "            context = f\"–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è {equipment_name}:\\n\"\n",
    "            context += db_info.iloc[0]['specs'] + \"\\n\\n–û–ø–∏—Å–∞–Ω–∏–µ: \" + db_info.iloc[0]['description']\n",
    "            prompt = f\"–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è:\\n{context}\\n\\n–ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:\"\n",
    "        else:\n",
    "            prompt = f\"–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ: {equipment_name}\\n–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:\"\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_length,\n",
    "                temperature=temperature,\n",
    "                top_k=50,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "        \n",
    "        description = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        description = description.replace(prompt, \"\").strip()\n",
    "        \n",
    "        return description\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "if __name__ == \"__main__\":\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–æ–º\n",
    "    generator = EquipmentDescriptionGenerator(use_web=True)\n",
    "    \n",
    "    equipment_names = [\n",
    "        \"–ú–∏–∫—Ä–æ—Å–∫–æ–ø Olympus CX23\",\n",
    "        \"–¶–µ–Ω—Ç—Ä–∏—Ñ—É–≥–∞ Eppendorf 5424\",\n",
    "        \"–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≥–µ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π Mindray BC-2800\"\n",
    "    ]\n",
    "    \n",
    "    for name in equipment_names:\n",
    "        print(f\"\\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è: {name}\")\n",
    "        \n",
    "        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö\n",
    "        web_description = generator.generate_description(name, use_web_data=True)\n",
    "        print(f\"–û–ø–∏—Å–∞–Ω–∏–µ —Å –≤–µ–±-–¥–∞–Ω–Ω—ã–º–∏:\\n{web_description}\")\n",
    "        \n",
    "        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö\n",
    "        local_description = generator.generate_description(name, use_web_data=False)\n",
    "        print(f\"\\n–û–ø–∏—Å–∞–Ω–∏–µ –±–µ–∑ –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö:\\n{local_description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TF-IDF –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è...\n",
      "üîç –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ TF-IDF...\n",
      "\n",
      "‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç:\n",
      "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ: \n",
      "        \n",
      "–û—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n",
      "- –ú–∞—Ç–µ—Ä–∏–∞–ª: –£–≥–ª–µ—Ä–æ–¥–∏—Å—Ç–∞—è —Å—Ç–∞–ª—å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)\n",
      "- –†–∞—Å—á–µ—Ç–Ω–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, ¬∞–°: 150\n",
      "- –î—É —Ç–µ–ø–ª–æ–æ–±–µ–Ω–Ω–∏–∫–∞: 32\n",
      "- –û–±—ä–µ–º –±–∞–∫–∞, –ª: 4,6\n",
      "- –°—Ö–µ–º–∞ –ø–æ—Ç–æ–∫–æ–≤: –û–¥–Ω–æ—Ö–æ–¥–æ–≤–æ–π\n",
      "- –°—Ä–µ–¥–∞ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ: –í–æ–¥–∞\n",
      "- –°—Ä–µ–¥–∞ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ: –í–æ–¥–∞\n",
      "- –†–∞—Å—Ö–æ–¥ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ: 11,2 —Ç—á\n",
      "- –†–∞—Å—Ö–æ–¥ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ: 4,67 —Ç—á\n",
      "- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—Ö–æ–¥–µ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 95\n",
      "- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—Ö–æ–¥–µ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 5\n",
      "- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 70\n",
      "- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ, ¬∞–°: 65\n",
      "- –ü–æ—Ç–µ—Ä–∏ –¥–∞–≤–ª–µ–Ω–∏—è –ø–æ –≥—Ä–µ—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–µ: 29,73 –∫–ü–∞\n",
      "- –ü–æ—Ç–µ—Ä–∏ –¥–∞–≤–ª–µ–Ω–∏—è –ø–æ –Ω–∞–≥—Ä–µ–≤–∞–µ–º–æ–π —Å—Ç–æ—Ä–æ–Ω–µ: 5,76 –∫–ü–∞\n",
      "- –¢–µ–ø–ª–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: 280000 –∫–∫–∞–ª—á\n",
      "- –ó–∞–ø–∞—Å –ø–ª–æ—â–∞–¥–∏ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏, %: 16,1\n",
      "- –ö–æ—ç—Ñ. —Ç–µ–ø–ª–æ–ø–µ—Ä–µ–¥–∞—á–∏: 4017\n",
      "- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–ª–æ—â–∞–¥—å, –º2: 2\n",
      "- –ß–∏—Å–ª–æ –ø–ª–∞—Å—Ç–∏–Ω: 50\n",
      "- –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è: –†–µ–∑—å–±–æ–≤–æ–µ\n",
      "- –ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ—Ä—Ç–æ–≤: -\n",
      "- –û—Ç–≤–µ—Ç–Ω—ã–µ —Ñ–ª–∞–Ω—Ü—ã: -\n",
      "- –†–∞—Å—á–µ—Ç–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ: 10\n",
      "- –ü—Ä–æ–±–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ, –∫–≥/—Å/—Å–º2: 14\n",
      "- –ú–∞—Å—Å–∞ –Ω–µ—Ç—Ç–æ, –∫–≥: 38,8\n",
      "- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –æ–±—ä–µ–º, –ª: 4,6\n",
      "\n",
      "–û–ø–∏—Å–∞–Ω–∏–µ: –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "class E8CompanyParser:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "\n",
    "    def parse_equipment_page(self, url: str) -> dict:\n",
    "        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            data = {\n",
    "                'name': self._get_text(soup, 'h1.product__title'),\n",
    "                'price': self._extract_price(soup),\n",
    "                'specs': self._extract_specs(soup),\n",
    "                'description': self._get_text(soup, 'div.product__desc'),\n",
    "                'images': self._extract_images(soup),\n",
    "                'link': url\n",
    "            }\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _get_text(self, soup: BeautifulSoup, selector: str) -> str:\n",
    "        \"\"\"–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä—É\"\"\"\n",
    "        element = soup.select_one(selector)\n",
    "        return self._clean_text(element.text) if element else \"\"\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤\"\"\"\n",
    "        return ' '.join(text.strip().split()) if text else \"\"\n",
    "\n",
    "    def _extract_price(self, soup: BeautifulSoup) -> str:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã\"\"\"\n",
    "        price_block = soup.find('div', class_='product__price')\n",
    "        if price_block:\n",
    "            price = price_block.find('span')\n",
    "            return self._clean_text(price.text) if price else \"–¶–µ–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É\"\n",
    "        return \"–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞\"\n",
    "\n",
    "    def _extract_specs(self, soup: BeautifulSoup) -> dict:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\"\"\"\n",
    "        specs = {}\n",
    "        names = soup.find_all('td', class_='char_name')\n",
    "        values = soup.find_all('td', class_='char_value')\n",
    "        \n",
    "        if len(names) == len(values):\n",
    "            for name, value in zip(names, values):\n",
    "                key = self._clean_text(name.find('span', itemprop='name').text) if name.find('span', itemprop='name') else \"\"\n",
    "                val = self._clean_text(value.find('span', itemprop='value').text) if value.find('span', itemprop='value') else \"\"\n",
    "                if key and val:\n",
    "                    specs[key] = val\n",
    "        return specs\n",
    "\n",
    "    def _extract_images(self, soup: BeautifulSoup) -> list:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
    "        images = []\n",
    "        gallery = soup.find('div', class_='product__gallery')\n",
    "        if gallery:\n",
    "            for img in gallery.find_all('img'):\n",
    "                if img.get('src'):\n",
    "                    img_url = urljoin('https://e8company.ru', img['src'])\n",
    "                    if img_url not in images:\n",
    "                        images.append(img_url)\n",
    "        return images\n",
    "\n",
    "class TFIDFDescriber:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = [\n",
    "            {\"name\": \"–¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ E8-S32\", \"specs\": {\"–ú–∞—Ç–µ—Ä–∏–∞–ª\": \"–£–≥–ª–µ—Ä–æ–¥–∏—Å—Ç–∞—è —Å—Ç–∞–ª—å\", \"–î–∞–≤–ª–µ–Ω–∏–µ\": \"10 –±–∞—Ä\"}, \n",
    "             \"description\": \"–ü–ª–∞—Å—Ç–∏–Ω—á–∞—Ç—ã–π —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –¥–ª—è —Å–∏—Å—Ç–µ–º –æ—Ç–æ–ø–ª–µ–Ω–∏—è. –†–∞–±–æ—á–µ–µ –¥–∞–≤–ª–µ–Ω–∏–µ –¥–æ 10 –±–∞—Ä.\"},\n",
    "            {\"name\": \"–ù–∞—Å–æ—Å ABC-200\", \"specs\": {\"–ú–æ—â–Ω–æ—Å—Ç—å\": \"2.2 –∫–í—Ç\", \"–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\": \"200 –ª/–º–∏–Ω\"}, \n",
    "             \"description\": \"–¶–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π –Ω–∞—Å–æ—Å –¥–ª—è –≤–æ–¥—ã —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é 200 –ª–∏—Ç—Ä–æ–≤ –≤ –º–∏–Ω—É—Ç—É.\"}\n",
    "        ]\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "\n",
    "    def generate_description(self, equipment_data: dict) -> str:\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è —á–µ—Ä–µ–∑ TF-IDF\"\"\"\n",
    "        query_text = self._prepare_query(equipment_data)\n",
    "        corpus = [self._prepare_query(item) for item in self.knowledge_base]\n",
    "        \n",
    "        tfidf_matrix = self.vectorizer.fit_transform(corpus + [query_text])\n",
    "        similarities = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix[:-1])\n",
    "        best_match_idx = np.argmax(similarities)\n",
    "        \n",
    "        if similarities[0][best_match_idx] > 0.3:\n",
    "            return self.knowledge_base[best_match_idx][\"description\"]\n",
    "        else:\n",
    "            return self._generate_default_description(equipment_data)\n",
    "\n",
    "    def _prepare_query(self, data: dict) -> str:\n",
    "        \"\"\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è TF-IDF\"\"\"\n",
    "        specs_text = \" \".join([f\"{k}_{v}\" for k, v in data['specs'].items()])\n",
    "        return f\"{data['name']} {specs_text}\"\n",
    "\n",
    "    def _generate_default_description(self, data: dict) -> str:\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\"\"\"\n",
    "        specs_text = \"\\n\".join([f\"- {k}: {v}\" for k, v in data['specs'].items()])\n",
    "        return f\"\"\"–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ: {data['name']}\n",
    "        \n",
    "–û—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n",
    "{specs_text}\n",
    "\n",
    "–û–ø–∏—Å–∞–Ω–∏–µ: –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π.\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö\n",
    "    parser = E8CompanyParser()\n",
    "    test_url = \"https://e8company.ru/catalog/teploobmenniki/e8_teploobmenniki/e8_s_32/\"\n",
    "    print(\"üîÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è...\")\n",
    "    equipment_data = parser.parse_equipment_page(test_url)\n",
    "    \n",
    "    if not equipment_data:\n",
    "        print(\"‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n",
    "        exit()\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è\n",
    "    print(\"üîç –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ TF-IDF...\")\n",
    "    describer = TFIDFDescriber()\n",
    "    description = describer.generate_description(equipment_data)\n",
    "    \n",
    "    print(\"\\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç:\")\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_42185 th {\n",
       "  font-size: 12pt;\n",
       "  background-color: #607D8B;\n",
       "  color: white;\n",
       "}\n",
       "#T_42185_row0_col0, #T_42185_row1_col0, #T_42185_row2_col0, #T_42185_row2_col1, #T_42185_row2_col2, #T_42185_row2_col3, #T_42185_row3_col0, #T_42185_row3_col1, #T_42185_row3_col2, #T_42185_row3_col3, #T_42185_row4_col0, #T_42185_row4_col1, #T_42185_row4_col2, #T_42185_row4_col3, #T_42185_row5_col0, #T_42185_row5_col1, #T_42185_row5_col2, #T_42185_row5_col3, #T_42185_row6_col0, #T_42185_row7_col0, #T_42185_row7_col1, #T_42185_row7_col2, #T_42185_row7_col3, #T_42185_row8_col0, #T_42185_row8_col1, #T_42185_row8_col2, #T_42185_row8_col3 {\n",
       "  text-align: left;\n",
       "  font-size: 12pt;\n",
       "}\n",
       "#T_42185_row0_col1, #T_42185_row1_col1, #T_42185_row6_col1 {\n",
       "  text-align: left;\n",
       "  font-size: 12pt;\n",
       "  background-color: #FFC107;\n",
       "}\n",
       "#T_42185_row0_col2, #T_42185_row1_col2, #T_42185_row6_col2 {\n",
       "  text-align: left;\n",
       "  font-size: 12pt;\n",
       "  background-color: #F44336;\n",
       "  color: white;\n",
       "}\n",
       "#T_42185_row0_col3, #T_42185_row1_col3, #T_42185_row6_col3 {\n",
       "  text-align: left;\n",
       "  font-size: 12pt;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_42185\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_42185_level0_col0\" class=\"col_heading level0 col0\" >–ú–µ—Ç—Ä–∏–∫–∞</th>\n",
       "      <th id=\"T_42185_level0_col1\" class=\"col_heading level0 col1\" >GPT-2 (Sber)</th>\n",
       "      <th id=\"T_42185_level0_col2\" class=\"col_heading level0 col2\" >TF-IDF</th>\n",
       "      <th id=\"T_42185_level0_col3\" class=\"col_heading level0 col3\" >Mistral (Ollama)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row0_col0\" class=\"data row0 col0\" >–ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏</td>\n",
       "      <td id=\"T_42185_row0_col1\" class=\"data row0 col1\" >–°—Ä–µ–¥–Ω–µ–µ (–µ—Å—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)</td>\n",
       "      <td id=\"T_42185_row0_col2\" class=\"data row0 col2\" >–ù–∏–∑–∫–æ–µ (—à–∞–±–ª–æ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã)</td>\n",
       "      <td id=\"T_42185_row0_col3\" class=\"data row0 col3\" >–í—ã—Å–æ–∫–æ–µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row1_col0\" class=\"data row1 col0\" >–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å</td>\n",
       "      <td id=\"T_42185_row1_col1\" class=\"data row1 col1\" >6/10</td>\n",
       "      <td id=\"T_42185_row1_col2\" class=\"data row1 col2\" >4/10</td>\n",
       "      <td id=\"T_42185_row1_col3\" class=\"data row1 col3\" >9/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row2_col0\" class=\"data row2 col0\" >–°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã</td>\n",
       "      <td id=\"T_42185_row2_col1\" class=\"data row2 col1\" >1-2 —Å–µ–∫</td>\n",
       "      <td id=\"T_42185_row2_col2\" class=\"data row2 col2\" ><0.5 —Å–µ–∫</td>\n",
       "      <td id=\"T_42185_row2_col3\" class=\"data row2 col3\" >3-10 —Å–µ–∫ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç GPU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row3_col0\" class=\"data row3 col0\" >–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ GPU</td>\n",
       "      <td id=\"T_42185_row3_col1\" class=\"data row3 col1\" >4GB+</td>\n",
       "      <td id=\"T_42185_row3_col2\" class=\"data row3 col2\" >–ù–µ—Ç</td>\n",
       "      <td id=\"T_42185_row3_col3\" class=\"data row3 col3\" >16GB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row4_col0\" class=\"data row4 col0\" >–û–±—É—á–µ–Ω–∏–µ</td>\n",
       "      <td id=\"T_42185_row4_col1\" class=\"data row4 col1\" >–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è</td>\n",
       "      <td id=\"T_42185_row4_col2\" class=\"data row4 col2\" >–ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è</td>\n",
       "      <td id=\"T_42185_row4_col3\" class=\"data row4 col3\" >–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row5_col0\" class=\"data row5 col0\" >–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è</td>\n",
       "      <td id=\"T_42185_row5_col1\" class=\"data row5 col1\" >–°—Ä–µ–¥–Ω—è—è</td>\n",
       "      <td id=\"T_42185_row5_col2\" class=\"data row5 col2\" >–í—ã—Å–æ–∫–∞—è</td>\n",
       "      <td id=\"T_42185_row5_col3\" class=\"data row5 col3\" >–í—ã—Å–æ–∫–∞—è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row6_col0\" class=\"data row6 col0\" >–¢–æ—á–Ω–æ—Å—Ç—å</td>\n",
       "      <td id=\"T_42185_row6_col1\" class=\"data row6 col1\" >65-70%</td>\n",
       "      <td id=\"T_42185_row6_col2\" class=\"data row6 col2\" >50-60%</td>\n",
       "      <td id=\"T_42185_row6_col3\" class=\"data row6 col3\" >80-85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row7_col0\" class=\"data row7 col0\" >–ü–ª—é—Å—ã</td>\n",
       "      <td id=\"T_42185_row7_col1\" class=\"data row7 col1\" >–ë—ã—Å—Ç—Ä–∞—è, –ª–µ–≥–∫–∞—è</td>\n",
       "      <td id=\"T_42185_row7_col2\" class=\"data row7 col2\" >–ü—Ä–æ—Å—Ç–æ—Ç–∞</td>\n",
       "      <td id=\"T_42185_row7_col3\" class=\"data row7 col3\" >–ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42185_row8_col0\" class=\"data row8 col0\" >–ú–∏–Ω—É—Å—ã</td>\n",
       "      <td id=\"T_42185_row8_col1\" class=\"data row8 col1\" >–£—Å—Ç–∞—Ä–µ–≤—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</td>\n",
       "      <td id=\"T_42185_row8_col2\" class=\"data row8 col2\" >–ü—Ä–∏–º–∏—Ç–∏–≤–Ω–æ—Å—Ç—å</td>\n",
       "      <td id=\"T_42185_row8_col3\" class=\"data row8 col3\" >–¢—Ä–µ–±—É–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4cd238490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n",
      "1. –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ ‚Üí Mistral 7B (—Ç—Ä–µ–±—É–µ—Ç—Å—è GPU 16GB+)\n",
      "2. –î–ª—è –±–∞–ª–∞–Ω—Å–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏/–∫–∞—á–µ—Å—Ç–≤–∞ ‚Üí GPT-2 (Sber)\n",
      "3. –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á ‚Üí TF-IDF + —à–∞–±–ª–æ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "data = {\n",
    "    '–ú–µ—Ç—Ä–∏–∫–∞': ['–ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏', '–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å', '–°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã', '–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ GPU', \n",
    "                '–û–±—É—á–µ–Ω–∏–µ', '–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è', '–¢–æ—á–Ω–æ—Å—Ç—å', '–ü–ª—é—Å—ã', '–ú–∏–Ω—É—Å—ã'],\n",
    "    'GPT-2 (Sber)': ['–°—Ä–µ–¥–Ω–µ–µ (–µ—Å—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)', '6/10', '1-2 —Å–µ–∫', '4GB+', \n",
    "                     '–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è', '–°—Ä–µ–¥–Ω—è—è', '65-70%', \n",
    "                     '–ë—ã—Å—Ç—Ä–∞—è, –ª–µ–≥–∫–∞—è', '–£—Å—Ç–∞—Ä–µ–≤—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞'],\n",
    "    'TF-IDF': ['–ù–∏–∑–∫–æ–µ (—à–∞–±–ª–æ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã)', '4/10', '<0.5 —Å–µ–∫', '–ù–µ—Ç', \n",
    "               '–ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è', '–í—ã—Å–æ–∫–∞—è', '50-60%', \n",
    "               '–ü—Ä–æ—Å—Ç–æ—Ç–∞', '–ü—Ä–∏–º–∏—Ç–∏–≤–Ω–æ—Å—Ç—å'],\n",
    "    'Mistral (Ollama)': ['–í—ã—Å–æ–∫–æ–µ', '9/10', '3-10 —Å–µ–∫ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç GPU)', '16GB+', \n",
    "                         '–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è', '–í—ã—Å–æ–∫–∞—è', '80-85%', \n",
    "                         '–ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏', '–¢—Ä–µ–±—É–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ –≤—ã–¥–µ–ª–µ–Ω–∏—è\n",
    "def highlight_cells(val):\n",
    "    colors = {\n",
    "        '–í—ã—Å–æ–∫–æ–µ': 'background-color: #4CAF50; color: white;',\n",
    "        '–°—Ä–µ–¥–Ω–µ–µ (–µ—Å—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)': 'background-color: #FFC107;',\n",
    "        '–ù–∏–∑–∫–æ–µ (—à–∞–±–ª–æ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã)': 'background-color: #F44336; color: white;',\n",
    "        '9/10': 'background-color: #4CAF50; color: white;',\n",
    "        '6/10': 'background-color: #FFC107;',\n",
    "        '4/10': 'background-color: #F44336; color: white;',\n",
    "        '80-85%': 'background-color: #4CAF50; color: white;',\n",
    "        '65-70%': 'background-color: #FFC107;',\n",
    "        '50-60%': 'background-color: #F44336; color: white;'\n",
    "    }\n",
    "    return colors.get(val, '')\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏\n",
    "styled_df = df.style\\\n",
    "    .set_properties(**{'text-align': 'left', 'font-size': '12pt'})\\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [('font-size', '12pt'), ('background-color', '#607D8B'), ('color', 'white')]}\n",
    "    ])\\\n",
    "    .applymap(highlight_cells, subset=pd.IndexSlice[:, ['GPT-2 (Sber)', 'TF-IDF', 'Mistral (Ollama)']])\\\n",
    "    .hide(axis='index')\\\n",
    "    .format(precision=2)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É\n",
    "display(styled_df)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤—ã–≤–æ–¥ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏\n",
    "print(\"\\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\")\n",
    "print(\"1. –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ ‚Üí Mistral 7B (—Ç—Ä–µ–±—É–µ—Ç—Å—è GPU 16GB+)\")\n",
    "print(\"2. –î–ª—è –±–∞–ª–∞–Ω—Å–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏/–∫–∞—á–µ—Å—Ç–≤–∞ ‚Üí GPT-2 (Sber)\")\n",
    "print(\"3. –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á ‚Üí TF-IDF + —à–∞–±–ª–æ–Ω—ã\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeppavlov_venv",
   "language": "python",
   "name": "deeppavlov_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
