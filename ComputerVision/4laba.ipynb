{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jRraMUbmZZBV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data():\n",
        "    (ds_train, ds_test), ds_info = tfds.load(\n",
        "        'oxford_iiit_pet:4.0.0',\n",
        "        split=['train[:80%]', 'train[80%:]'],\n",
        "        with_info=True,\n",
        "        as_supervised=True\n",
        "    )\n",
        "\n",
        "    def preprocess(image, mask):\n",
        "        image = tf.cast(image, tf.float32) / 255.0\n",
        "        mask = tf.cast(mask, tf.int32) - 1  # Маски: 1, 2, 3 -> 0, 1, 2\n",
        "        image = tf.image.resize(image, [128, 128])\n",
        "        mask = tf.expand_dims(mask, axis=-1)  # Добавляем канал: [H, W] -> [H, W, 1]\n",
        "        mask = tf.image.resize(mask, [128, 128], method='nearest')  # Изменяем размер\n",
        "        mask = tf.squeeze(mask, axis=-1)  # Убираем канал: [H, W, 1] -> [H, W]\n",
        "        return image, mask\n",
        "\n",
        "    ds_train = ds_train.map(preprocess).cache().shuffle(1000).batch(8).prefetch(tf.data.AUTOTUNE)\n",
        "    ds_test = ds_test.map(preprocess).batch(8).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds_train, ds_test, ds_info"
      ],
      "metadata": {
        "id": "zA6L2BJQcat9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice Loss\n",
        "def dice_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
        "    return 1 - (2. * intersection + 1.) / (union + 1.)"
      ],
      "metadata": {
        "id": "xUR2GuE5cgU6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Комбинированная функция потерь\n",
        "def combined_loss(y_true, y_pred):\n",
        "    ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)(y_true, y_pred)\n",
        "    d_loss = dice_loss(tf.one_hot(y_true, depth=3), y_pred)\n",
        "    return ce_loss + d_loss"
      ],
      "metadata": {
        "id": "9q4J03abcpMm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Блок энкодера\n",
        "def encoder_block(inputs, filters):\n",
        "    x = layers.Conv2D(filters, 3, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    p = layers.MaxPooling2D(2)(x)\n",
        "    return x, p\n"
      ],
      "metadata": {
        "id": "-y5-2JwkcrJs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Блок декодера\n",
        "def decoder_block(inputs, skip, filters):\n",
        "    x = layers.UpSampling2D(2)(inputs)\n",
        "    x = layers.Concatenate()([x, skip])\n",
        "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "ULG-KVJlctT0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Создание U-Net\n",
        "def build_unet():\n",
        "    inputs = layers.Input(shape=(128, 128, 3))\n",
        "\n",
        " # Энкодер\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    # Бутылочное горлышко\n",
        "    b = layers.Conv2D(1024, 3, padding='same')(p4)\n",
        "    b = layers.BatchNormalization()(b)\n",
        "    b = layers.LeakyReLU(alpha=0.1)(b)\n",
        "    b = layers.Conv2D(1024, 3, padding='same')(b)\n",
        "    b = layers.BatchNormalization()(b)\n",
        "    b = layers.LeakyReLU(alpha=0.1)(b)\n",
        "\n",
        "    # Декодер\n",
        "    d1 = decoder_block(b, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        ""
      ],
      "metadata": {
        "id": "rPCc5jZHczco"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выходной слой\n",
        "    outputs = layers.Conv2D(3, 1, padding='same', activation='softmax')(d4)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LunIC13FfuAS",
        "outputId": "04377027-7f02-4b1e-ac43-ec156b7bd5be"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-35-1596335256.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-35-1596335256.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    outputs = layers.Conv2D(3, 1, padding='same', activation='softmax')(d4)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Основной код\n",
        "if __name__ == '__main__':\n",
        "    # Загрузка данных\n",
        "    ds_train, ds_test, ds_info = load_and_preprocess_data()\n",
        "\n",
        "    # Создание и компиляция модели\n",
        "    model = build_unet()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "        loss=combined_loss,\n",
        "        metrics=[tf.keras.metrics.MeanIoU(num_classes=3)]\n",
        "    )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GXsBhMHCc5UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Коллбэки\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_mean_io_u', mode='max')\n",
        "    ]\n",
        ""
      ],
      "metadata": {
        "id": "R4_NwH9vc67q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Обучение\n",
        "    history = model.fit(\n",
        "        ds_train,\n",
        "        validation_data=ds_test,\n",
        "        epochs=20,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "metadata": {
        "id": "-1PEqwNlc8Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Визуализация IoU\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(history.history['mean_io_u'], label='Train IoU')\n",
        "    plt.plot(history.history['val_mean_io_u'], label='Val IoU')\n",
        "    plt.title('Mean IoU over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean IoU')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cf-lNRy5gk-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}